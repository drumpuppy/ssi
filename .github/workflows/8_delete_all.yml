name: 8 /!\ Destroy K8s Cluster and Helm Charts /!\

on:
  workflow_dispatch:

jobs:
  destroy:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout repository
        uses: actions/checkout@v2

      - name: Install Helm
        run: |
          curl -fsSL -o get_helm.sh https://raw.githubusercontent.com/helm/helm/main/scripts/get-helm-3
          chmod 700 get_helm.sh
          ./get_helm.sh

      - name: Install Scaleway CLI
        run: |
          curl -s https://raw.githubusercontent.com/scaleway/scaleway-cli/master/scripts/get.sh | sh
          scw version

      - name: Configure Scaleway CLI
        env:
          SCW_ACCESS_KEY: ${{ secrets.SCW_ACCESS_KEY }}
          SCW_SECRET_KEY: ${{ secrets.SCW_SECRET_KEY }}
          SCW_DEFAULT_PROJECT_ID: ${{ secrets.SCW_PROJECT_ID }}
          SCW_DEFAULT_ORGANIZATION_ID: ${{ secrets.SCW_ORGANIZATION_ID }}
          SCW_DEFAULT_REGION: fr-par
          SCW_DEFAULT_ZONE: fr-par-1
        run: |
          mkdir -p ~/.config/scw
          touch ~/.config/scw/config.yaml
          scw config set access-key="${SCW_ACCESS_KEY}"
          scw config set secret-key="${SCW_SECRET_KEY}"
          scw config set default-organization-id="${SCW_DEFAULT_ORGANIZATION_ID}"
          scw config set default-project-id="${SCW_DEFAULT_PROJECT_ID}"
          scw config set default-region="${SCW_DEFAULT_REGION}"
          scw config set default-zone="${SCW_DEFAULT_ZONE}"

          export SCW_DEFAULT_ZONE=$(scw config get default-zone)
          echo "SCW_DEFAULT_ZONE=$SCW_DEFAULT_ZONE" >> $GITHUB_ENV
          export SCW_SECRET_KEY="${SCW_SECRET_KEY}"
          echo "SCW_SECRET_KEY=${SCW_SECRET_KEY}" >> $GITHUB_ENV
          export SCW_DEFAULT_PROJECT_ID=$(scw config get default-project-id)
          echo "SCW_DEFAULT_PROJECT_ID=${SCW_DEFAULT_PROJECT_ID}" >> $GITHUB_ENV


      - name: Configure kubeconfig
        run: |
          mkdir -p ~/.kube
          cluster_id=$(scw k8s cluster list name=k8s-cluster project-id=${{ secrets.SCW_PROJECT_ID }} --output json | jq -r '.[0].id')
          if [[ -z "$cluster_id" || "$cluster_id" == "null" ]]; then
            echo "Error: Kubernetes cluster ID not found or is not valid."
            exit 1
          fi
          scw k8s kubeconfig get "$cluster_id" > ~/.kube/config

      - name: Create snapshot from PVCs
        run: |
          PVC_LIST=("default elasticsearch-master-elasticsearch-master-0" "doctobobo mysql-pvc")

          echo "üìå Debug: Checking SCW_DEFAULT_ZONE: ${SCW_DEFAULT_ZONE}"

          if [[ -z "$SCW_DEFAULT_ZONE" ]]; then
            echo "‚ùå SCW_DEFAULT_ZONE is empty! Exiting..."
            exit 1
          fi

          echo "üìå Debug: Checking SCW_PROJECT_ID: ${SCW_PROJECT_ID}"

          if [[ -z "$SCW_DEFAULT_PROJECT_ID" ]]; then
            echo "‚ùå SCW_DEFAULT_PROJECT_ID is empty! Exiting..."
            exit 1
          fi

          echo "üìå Debug: Listing all Scaleway Block Storage volumes"
          curl -s -H "X-Auth-Token: ${SCW_SECRET_KEY}" \
               "https://api.scaleway.com/block/v1alpha1/zones/${SCW_DEFAULT_ZONE}/volumes" | tee volumes.json

          echo "üìå Debug: Displaying volumes.json"
          cat volumes.json | jq '.'

          for entry in "${PVC_LIST[@]}"; do
            namespace=$(echo $entry | awk '{print $1}')
            pvc=$(echo $entry | awk '{print $2}')

            echo "üîç Retrieving Scaleway volume ID for PVC $pvc in namespace $namespace..."

            pvc_name=$(kubectl get pvc $pvc -n $namespace -o jsonpath='{.spec.volumeName}' 2>/dev/null || echo "")
            echo "üìå Debug: Retrieved PVC Name: $pvc_name"

            if [ -z "$pvc_name" ]; then
              echo "‚ö†Ô∏è PVC $pvc not found in namespace $namespace, skipping..."
              continue
            fi

            echo "üîç Searching for volume in Scaleway Block Storage matching PVC name: $pvc_name"
            volume_id=$(jq -r --arg pvc_name "$pvc_name" '.volumes[] | select(.name | contains($pvc_name)) | .id' volumes.json)
            echo "üìå Debug: Scaleway Volume ID Found: $volume_id"

            if [ -z "$volume_id" ] || [ "$volume_id" == "null" ]; then
              echo "‚ö†Ô∏è No Scaleway volume found for PVC $pvc ($pvc_name), skipping..."
              continue
            fi

            echo "‚úÖ Creating snapshot for PVC $pvc ($pvc_name) in namespace $namespace..."
            snapshot_name="$pvc-$(date +%Y%m%d%H%M%S)"

            curl -X POST -H "X-Auth-Token: ${SCW_SECRET_KEY}" \
                 -H "Content-Type: application/json" \
                 -d '{
                      "name": "'"$snapshot_name"'",
                      "volume_id": "'"$volume_id"'",
                      "project_id": "'"$SCW_DEFAULT_PROJECT_ID"'"
                    }' \
                 "https://api.scaleway.com/block/v1alpha1/zones/${SCW_DEFAULT_ZONE}/snapshots"
          done

      - name: Uninstall All Helm Charts
        continue-on-error: true
        run: |
          echo "Uninstalling Helm charts..."
      
          if helm list -n default | grep -q 'prometheus-operator'; then
            helm uninstall prometheus-operator --namespace default
          else
            echo "Prometheus Operator not installed in the default namespace."
          fi
      
          if helm list -n default | grep -q 'logstash'; then
            helm uninstall logstash --namespace default
          else
            echo "Logstash not installed in the default namespace."
          fi
      
          if helm list -n default | grep -q 'filebeat'; then
            helm uninstall filebeat --namespace default
          else
            echo "Filebeat not installed in the default namespace."
          fi
      
          if helm list -n default | grep -q 'elasticsearch'; then
            helm uninstall elasticsearch --namespace default
          else
            echo "Elasticsearch not installed in the default namespace."
          fi
      
          if helm list -n istio-system | grep -q 'istio-ingress'; then
            helm uninstall istio-ingress --namespace istio-system
          else
            echo "Istio Ingress not installed in the istio-system namespace."
          fi
      
          if helm list -n istio-system | grep -q 'istiod'; then
            helm uninstall istiod --namespace istio-system
          else
            echo "Istiod not installed in the istio-system namespace."
          fi

          if helm list -n default | grep -q 'falco'; then
            helm uninstall falco --namespace default
          else
            echo "Falco not installed in the default namespace."
          fi
      
          if helm list -n ingress-nginx | grep -q 'ingress-nginx'; then
            helm uninstall ingress-nginx --namespace ingress-nginx
          else
            echo "Ingress-nginx not installed in the default namespace."
          fi
      
          if helm list -n default | grep -q 'kibana'; then
            echo "Uninstalling Kibana in the background..."
            helm uninstall kibana --namespace default --wait=false &
          else
            echo "Kibana not installed in the default namespace."
          fi

          kubectl delete -k ./helm/wazuh-kubernetes/wazuh/
      
      - name: Clean Up Kibana Resources
        continue-on-error: true
        run: |
          echo "Attempting to clean up Kibana resources..."
          kubectl delete sa post-delete-kibana-kibana -n default || echo "ServiceAccount already deleted or not found"
          kubectl delete cm kibana-kibana-helm-scripts -n default || echo "ConfigMap already deleted or not found"
          kubectl delete job post-delete-kibana-kibana -n default || echo "Job already deleted or not found"
          kubectl delete role post-delete-kibana-kibana -n default || echo "Role already deleted or not found"
          kubectl delete rolebinding post-delete-kibana-kibana -n default || echo "RoleBinding already deleted or not found"
          kubectl delete secret kibana-kibana-es-token -n default || echo "Secret already deleted or not found"
          kubectl delete secret sh.helm.release.v1.kibana.v1 -n default || echo "Helm release secret already deleted or not found"
      
      - name: Clean Up Doctobobo
        continue-on-error: true
        run: |
          echo "Attempting to clean up Doctobobo resources..."
          kubectl delete -f ./doctobobo/backend/mysql-deployment.yaml -n doctobobo
          kubectl delete -f ./doctobobo/backend/backend-deployment.yaml -n doctobobo
          kubectl delete -f doctobobo/frontend/frontend-deployment.yaml -n doctobobo

      - name: Delete network resources
        continue-on-error: true
        run: |
          kubectl delete -f ./Ingress/network.yaml
          kubectl delete -f https://raw.githubusercontent.com/kubernetes/ingress-nginx/main/deploy/static/provider/cloud/deploy.yaml
          kubectl delete -f https://github.com/cert-manager/cert-manager/releases/download/v1.11.0/cert-manager.yaml
          kubectl delete -f ./ingress/clusterIssuer.yaml
      
      - name: List and Delete All PVCs
        run: |
          # Get all PVC names in the default namespace
          pvc_names=$(kubectl get pvc -o jsonpath='{.items[*].metadata.name}')
          
          if [ -z "$pvc_names" ]; then
            echo "No PVCs found."
          else
            for pvc_name in $pvc_names; do
              echo "Deleting PVC $pvc_name..."
              kubectl delete pvc "$pvc_name" || echo "Failed to delete PVC $pvc_name. It may be in use."
            done
          fi

      - name: Log in to Scaleway Container Registry
        run: |
          echo "${{ secrets.SCW_SECRET_KEY }}" | docker login rg.fr-par.scw.cloud -u "${{ secrets.SCW_ACCESS_KEY }}" --password-stdin

      - name: Clean existing images and Kubernetes resources
        run: |
          echo "Deleting images in frontend namespace..."
          frontend_namespace_id=$(scw registry namespace list name=frontend --output json | jq -r '.[0].id')
          if [ -n "$frontend_namespace_id" ]; then
            frontend_images=$(scw registry image list namespace-id="$frontend_namespace_id" region=fr-par --output json | jq -r '.[].id')
            if [ -n "$frontend_images" ]; then
              for image_id in $frontend_images; do
                echo "Deleting image $image_id in frontend namespace..."
                scw registry image delete image-id="$image_id" region=fr-par || true
              done
            else
              echo "No images found in frontend namespace."
            fi
          else
            echo "Frontend namespace not found."
          fi
          
          echo "Deleting images in backend2 namespace..."
          backend_namespace_id=$(scw registry namespace list name=backend2 --output json | jq -r '.[0].id')
          if [ -n "$backend_namespace_id" ]; then
            backend_images=$(scw registry image list namespace-id="$backend_namespace_id" region=fr-par --output json | jq -r '.[].id')
            if [ -n "$backend_images" ]; then
              for image_id in $backend_images; do
                echo "Deleting image $image_id in backend2 namespace..."
                scw registry image delete image-id="$image_id" region=fr-par || true
              done
            else
              echo "No images found in backend2 namespace."
            fi
          else
            echo "Backend2 namespace not found."
          fi
      
          echo "Deleting frontend Kubernetes resources..."
          kubectl delete deployment frontend || true
          kubectl delete service frontend-service || true
          
          echo "Deleting backend Kubernetes resources..."
          kubectl delete deployment backend || true
          kubectl delete service backend-service || true

      - name: Set up Terraform
        uses: hashicorp/setup-terraform@v1
        with:
          cli_config_credentials_hostname: app.terraform.io
          cli_config_credentials_token: ${{ secrets.TF_CLOUD_TOKEN }}
          terraform_version: latest

      - name: Terraform Init for Destroy
        working-directory: ./infra
        env:
          TF_VAR_scw_access_key: ${{ secrets.SCW_ACCESS_KEY }}
          TF_VAR_scw_secret_key: ${{ secrets.SCW_SECRET_KEY }}
          TF_VAR_scw_project_id: ${{ secrets.SCW_PROJECT_ID }}
        run: terraform init

      - name: Terraform Destroy
        working-directory: ./infra
        env:
          TF_VAR_scw_access_key: ${{ secrets.SCW_ACCESS_KEY }}
          TF_VAR_scw_secret_key: ${{ secrets.SCW_SECRET_KEY }}
          TF_VAR_scw_project_id: ${{ secrets.SCW_PROJECT_ID }}
        run: terraform destroy -auto-approve

      
