name: 4 Deploy Configs

on:
  workflow_dispatch:

jobs:
  deploy:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout repository
        uses: actions/checkout@v2

      - name: Install Helm
        run: |
          curl -fsSL -o get_helm.sh https://raw.githubusercontent.com/helm/helm/main/scripts/get-helm-3
          chmod 700 get_helm.sh
          ./get_helm.sh

      - name: Install Scaleway CLI
        run: |
          curl -s https://raw.githubusercontent.com/scaleway/scaleway-cli/master/scripts/get.sh | sh
          scw version

      - name: Configure Scaleway CLI
        env:
          SCW_ACCESS_KEY: ${{ secrets.SCW_ACCESS_KEY }}
          SCW_SECRET_KEY: ${{ secrets.SCW_SECRET_KEY }}
          SCW_DEFAULT_PROJECT_ID: ${{ secrets.SCW_PROJECT_ID }}
          SCW_DEFAULT_ORGANIZATION_ID: ${{ secrets.SCW_ORGANIZATION_ID }}
          SCW_DEFAULT_REGION: fr-par
          SCW_DEFAULT_ZONE: fr-par-1
        run: |
          mkdir -p ~/.config/scw
          touch ~/.config/scw/config.yaml
          scw config set access-key="${SCW_ACCESS_KEY}"
          scw config set secret-key="${SCW_SECRET_KEY}"
          scw config set default-organization-id="${SCW_DEFAULT_ORGANIZATION_ID}"
          scw config set default-project-id="${SCW_DEFAULT_PROJECT_ID}"
          scw config set default-region="${SCW_DEFAULT_REGION}"
          scw config set default-zone="${SCW_DEFAULT_ZONE}"

          export SCW_DEFAULT_ZONE=$(scw config get default-zone)
          echo "SCW_DEFAULT_ZONE=$SCW_DEFAULT_ZONE" >> $GITHUB_ENV
          export SCW_SECRET_KEY="${SCW_SECRET_KEY}"
          echo "SCW_SECRET_KEY=${SCW_SECRET_KEY}" >> $GITHUB_ENV
          export SCW_DEFAULT_PROJECT_ID=$(scw config get default-project-id)
          echo "SCW_DEFAULT_PROJECT_ID=${SCW_DEFAULT_PROJECT_ID}" >> $GITHUB_ENV

      - name: Configure kubeconfig
        run: |
          mkdir -p ~/.kube
          cluster_id=$(scw k8s cluster list name=k8s-cluster project-id=${{ secrets.SCW_PROJECT_ID }} --output json | jq -r '.[0].id')
          if [[ -z "$cluster_id" || "$cluster_id" == "null" ]]; then
            echo "Error: Kubernetes cluster ID not found or is not valid."
            exit 1
          fi
          echo "Cluster ID: $cluster_id"
          scw k8s kubeconfig get "$cluster_id" > ~/.kube/config
          export KUBECONFIG=~/.kube/config  # Ensure it's set in GitHub runner

      - name: Fetch Kibana Password & Deploy Data Views
        run: |
          export KUBECONFIG=~/.kube/config
          
          # Get Kibana password
          KIBANA_PASSWORD=$(kubectl get secret elasticsearch-master-credentials -n default -o jsonpath='{.data.password}' | base64 -d)
          
          # Get Kibana pod name dynamically
          KIBANA_POD=$(kubectl get pods -n default -l app=kibana -o jsonpath='{.items[0].metadata.name}')
          
          echo "Uploading data view configuration files to Kibana pod: $KIBANA_POD"
          
          # Define files to upload from the ./config folder
          FILES=(
            config/export-istio-dv.ndjson
            config/export-istio-search.ndjson
            config/export-falco-dv.ndjson
            config/export-falco-search.ndjson
            config/export-wazuh-dv.ndjson
            config/export-wazuh-search.ndjson
          )
          
          for FILE in "${FILES[@]}"; do
            FILE_NAME=$(basename "$FILE")
            echo "Uploading $FILE_NAME..."
            kubectl cp "./$FILE" "$KIBANA_POD:/usr/share/kibana/config/$FILE_NAME" -n default
            
            echo "Importing $FILE_NAME into Kibana..."
            kubectl exec -it "$KIBANA_POD" -n default -- \
              curl -X POST "http://localhost:5601/api/saved_objects/_import" \
              -H "kbn-xsrf: true" \
              -F "file=@/usr/share/kibana/config/$FILE_NAME" \
              -u "elastic:$KIBANA_PASSWORD"
          done
          
          echo "‚úÖ Kibana Data Views successfully imported!"

      - name: Fetch Wazuh Password & Deploy Configs
        run: |
          export KUBECONFIG=~/.kube/config

          # ‚úÖ V√©rifier que le secret Wazuh existe avant de l'extraire
          SECRET_NAME="wazuh-api-cred"
          if kubectl get secret $SECRET_NAME -n wazuh > /dev/null 2>&1; then
            WAZUH_PASSWORD=$(kubectl get secret $SECRET_NAME -n wazuh -o jsonpath='{.data.password}' | base64 -d)
          else
            echo "‚ö†Ô∏è Wazuh secret not found: $SECRET_NAME"
            exit 1
          fi

          # ‚úÖ Trouver dynamiquement le StatefulSet Wazuh Manager (Master + Worker)
          WAZUH_STATEFULSETS=("wazuh-manager-master" "wazuh-manager-worker")

          # ‚úÖ Trouver le pod principal du Wazuh Manager (Master)
          WAZUH_POD=$(kubectl get pods -n wazuh -l app=wazuh-manager -o jsonpath='{.items[0].metadata.name}' --ignore-not-found)
          if [[ -z "$WAZUH_POD" ]]; then
            echo "‚ö†Ô∏è Wazuh Manager pod not found. Aborting."
            exit 1
          fi

          echo "Uploading configuration files to Wazuh pod: $WAZUH_POD"

          # üìå D√©finir les fichiers √† charger (dans ./config)
          FILES=(
            config/wazuh-rules.xml
            config/wazuh-decoders.xml
            config/wazuh-lists.xml
          )

          for FILE in "${FILES[@]}"; do
            FILE_NAME=$(basename "$FILE")
            echo "Uploading $FILE_NAME..."
            kubectl cp "./$FILE" "$WAZUH_POD:/var/ossec/etc/$FILE_NAME" -n wazuh
          done

          echo "Restarting Wazuh Manager components to apply changes..."
          for STS in "${WAZUH_STATEFULSETS[@]}"; do
            echo "üîÑ Restarting $STS ..."
            kubectl rollout restart statefulset "$STS" -n wazuh
          done

          echo "‚úÖ Wazuh configuration successfully updated!"